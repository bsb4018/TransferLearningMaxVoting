{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "votingClassifier-covidCXR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f42325992694c7ea4f57f8ffe8f7faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34ab82bc7a1c4798a047c28946c7e4e4",
              "IPY_MODEL_b3ad614c9ee44e16bcc79a923d0cca7b",
              "IPY_MODEL_a69f69efce064dd3aef3c270b3674bdb"
            ],
            "layout": "IPY_MODEL_86b26e990ded40a19a7f5ecc53102953"
          }
        },
        "34ab82bc7a1c4798a047c28946c7e4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f44d7d4ba10a4950bda77300a4da17ad",
            "placeholder": "​",
            "style": "IPY_MODEL_603f11fb5e7d4b2bb85f8ad713a4b722",
            "value": "100%"
          }
        },
        "b3ad614c9ee44e16bcc79a923d0cca7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc56506804ea49e5b49184dd98ce7b1b",
            "max": 32342954,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8b08b90558e4de18b9d42eb566c159b",
            "value": 32342954
          }
        },
        "a69f69efce064dd3aef3c270b3674bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8afda8f3b3b84381b3baedda6e8ee4ca",
            "placeholder": "​",
            "style": "IPY_MODEL_e16b5123449f43b383e8a75dfa541769",
            "value": " 30.8M/30.8M [00:00&lt;00:00, 50.2MB/s]"
          }
        },
        "86b26e990ded40a19a7f5ecc53102953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44d7d4ba10a4950bda77300a4da17ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "603f11fb5e7d4b2bb85f8ad713a4b722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc56506804ea49e5b49184dd98ce7b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8b08b90558e4de18b9d42eb566c159b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8afda8f3b3b84381b3baedda6e8ee4ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e16b5123449f43b383e8a75dfa541769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVkeccCUzetw",
        "outputId": "d6ea0bed-4a23-456f-c08d-ddc7f2685979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jul  8 10:34:37 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchensemble"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x9UyRzB1cO1",
        "outputId": "8b1d1caa-76fd-433b-f191-ec378db6305b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchensemble in /usr/local/lib/python3.7/dist-packages (0.1.7)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from torchensemble) (0.12.0+cu113)\n",
            "Requirement already satisfied: scikit-learn>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from torchensemble) (1.0.2)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torchensemble) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->torchensemble) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->torchensemble) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->torchensemble) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->torchensemble) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->torchensemble) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.2.2->torchensemble) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.2.2->torchensemble) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->torchensemble) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->torchensemble) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->torchensemble) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->torchensemble) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Function\n",
        "from torchvision import models\n",
        "from torchvision import utils\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data.dataloader import default_collate"
      ],
      "metadata": {
        "id": "k_R5P45lzh_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50a83k53ziCW",
        "outputId": "3e1153b3-cfe1-4d1c-a05f-94fedf7ba3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the dataset loader\n",
        "input_path = 'drive/MyDrive/cxr_splitdata/'\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "data_transforms = {\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.RandomCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    'val':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    'test':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "261DPqWRziEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = {\n",
        "    'train': \n",
        "    datasets.ImageFolder(input_path + 'train', data_transforms['train']),\n",
        "    'val': \n",
        "    datasets.ImageFolder(input_path + 'val', data_transforms['val']),  \n",
        "    'test': \n",
        "    datasets.ImageFolder(input_path + 'test', data_transforms['test'])\n",
        "}\n"
      ],
      "metadata": {
        "id": "FgTT92c6ziHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {\n",
        "    'train':\n",
        "    torch.utils.data.DataLoader(image_datasets['train'],\n",
        "                                batch_size=32,\n",
        "                                shuffle=True,\n",
        "                                #collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)),\n",
        "                                num_workers=0),\n",
        "    'val':\n",
        "    torch.utils.data.DataLoader(image_datasets['val'],\n",
        "                                batch_size=32,\n",
        "                                shuffle=False,\n",
        "                                #collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)),\n",
        "                                num_workers=0), \n",
        "    \n",
        "    'test':\n",
        "    torch.utils.data.DataLoader(image_datasets['test'],\n",
        "                                batch_size=32,\n",
        "                                shuffle=False,\n",
        "                                #collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)),\n",
        "                                num_workers=0)\n",
        "}"
      ],
      "metadata": {
        "id": "Y_AcoQOjziJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LKTLpLTiztwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MANUAL VGG IMPLEMENTED MODEL\n",
        "VGG_types = {\n",
        "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG16\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\",],\n",
        "    \"VGG19\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\",],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG_net(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=2):\n",
        "        super(VGG_net, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.conv_layers = self.create_conv_layers(VGG_types[\"VGG11\"])\n",
        "\n",
        "        self.fcs = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fcs(x)\n",
        "        return x\n",
        "\n",
        "    def create_conv_layers(self, architecture):\n",
        "        layers = []\n",
        "        in_channels = self.in_channels\n",
        "\n",
        "        for x in architecture:\n",
        "            if type(x) == int:\n",
        "                out_channels = x\n",
        "\n",
        "                layers += [\n",
        "                    nn.Conv2d(\n",
        "                        in_channels=in_channels,\n",
        "                        out_channels=out_channels,\n",
        "                        kernel_size=(3, 3),\n",
        "                        stride=(1, 1),\n",
        "                        padding=(1, 1),\n",
        "                    ),\n",
        "                    nn.BatchNorm2d(x),\n",
        "                    nn.ReLU(),\n",
        "                ]\n",
        "                in_channels = x\n",
        "            elif x == \"M\":\n",
        "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
        "\n",
        "        return nn.Sequential(*layers)\n"
      ],
      "metadata": {
        "id": "FC5-A6cI4t5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#in_channels = 3\n",
        "#num_classes = 2\n",
        "#base_estimator = CNN(in_channels=in_channels, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "0qk435Q0ziOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels = 3\n",
        "num_classes = 2\n",
        "base_estimator = VGG_net(in_channels=3, num_classes=2)\n",
        "print(base_estimator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDcBBu0O46OX",
        "outputId": "606afe75-5511-4b09-8461-0e5aace9d967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG_net(\n",
            "  (conv_layers): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU()\n",
            "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU()\n",
            "    (14): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): ReLU()\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU()\n",
            "    (21): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): ReLU()\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU()\n",
            "    (28): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fcs): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_loader = dataloaders['train']\n",
        "val_loader = dataloaders['val']\n",
        "test_loader = dataloaders['test']"
      ],
      "metadata": {
        "id": "_XVgZ87tziVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.003\n",
        "weight_decay = 0.3\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "gnTkFGkWSKZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchensemble import VotingClassifier"
      ],
      "metadata": {
        "id": "IJ6PYBs1SHK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ensemble\n",
        "ensemble = VotingClassifier(\n",
        "    estimator=base_estimator,              # here is your deep learning model\n",
        "    n_estimators=5,                        # number of base estimators\n",
        ")"
      ],
      "metadata": {
        "id": "fTp2N58qziYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the criterion\n",
        "criterion = nn.CrossEntropyLoss()           # training objective\n",
        "ensemble.set_criterion(criterion)"
      ],
      "metadata": {
        "id": "mjrtMUZazib5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the optimizer\n",
        "ensemble.set_optimizer(\n",
        "    \"Adam\",                                 # type of parameter optimizer\n",
        "    lr=learning_rate,                       # learning rate of parameter optimizer\n",
        "    weight_decay=weight_decay              # weight decay of parameter optimizer\n",
        ")\n"
      ],
      "metadata": {
        "id": "uyyALeWl0AVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the learning rate scheduler\n",
        "ensemble.set_scheduler(\n",
        "    \"CosineAnnealingLR\",                    # type of learning rate scheduler\n",
        "    T_max=epochs                           # additional arguments on the scheduler\n",
        ")"
      ],
      "metadata": {
        "id": "LOU9D5w70AYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the ensemble\n",
        "ensemble.fit(\n",
        "    train_loader,\n",
        "    epochs=epochs                          # number of training epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cSMYzoR0Amg",
        "outputId": "766bd18b-bc10-470f-eb5f-f165e1b60694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimator: 000 | Epoch: 000 | Batch: 000 | Loss: 0.72659 | Correct: 15/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 100 | Loss: 1.16479 | Correct: 20/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 000 | Loss: 0.71479 | Correct: 13/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 100 | Loss: 1.15906 | Correct: 22/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 000 | Loss: 0.69824 | Correct: 19/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 100 | Loss: 1.17345 | Correct: 18/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 000 | Loss: 0.67149 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 100 | Loss: 0.74384 | Correct: 17/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 000 | Loss: 0.73685 | Correct: 13/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 100 | Loss: 4.83019 | Correct: 11/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 000 | Loss: 0.78310 | Correct: 16/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 100 | Loss: 0.60630 | Correct: 20/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 000 | Loss: 0.95625 | Correct: 16/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 100 | Loss: 0.65333 | Correct: 25/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 000 | Loss: 0.83866 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 100 | Loss: 0.63599 | Correct: 21/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 000 | Loss: 0.72412 | Correct: 18/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 100 | Loss: 0.70771 | Correct: 11/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 000 | Loss: 1.84104 | Correct: 18/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 100 | Loss: 0.79201 | Correct: 15/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 000 | Loss: 0.67864 | Correct: 17/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 100 | Loss: 0.69517 | Correct: 12/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 000 | Loss: 0.66770 | Correct: 17/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 100 | Loss: 0.69963 | Correct: 15/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 000 | Loss: 0.64763 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 100 | Loss: 0.69901 | Correct: 13/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 000 | Loss: 0.69404 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 100 | Loss: 0.68419 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 000 | Loss: 0.77087 | Correct: 15/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 100 | Loss: 0.65204 | Correct: 19/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 000 | Loss: 0.69129 | Correct: 19/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 100 | Loss: 0.69275 | Correct: 17/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 000 | Loss: 0.68457 | Correct: 13/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 100 | Loss: 0.69222 | Correct: 16/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 000 | Loss: 0.63999 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 100 | Loss: 0.68642 | Correct: 24/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 000 | Loss: 0.71542 | Correct: 20/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 100 | Loss: 0.67152 | Correct: 23/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 000 | Loss: 0.70606 | Correct: 10/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 100 | Loss: 0.69494 | Correct: 15/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 000 | Loss: 0.69268 | Correct: 17/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 100 | Loss: 0.69413 | Correct: 14/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 000 | Loss: 0.69219 | Correct: 17/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 100 | Loss: 0.69328 | Correct: 16/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 000 | Loss: 0.63595 | Correct: 21/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 100 | Loss: 0.58324 | Correct: 24/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 000 | Loss: 0.69003 | Correct: 18/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 100 | Loss: 0.69797 | Correct: 13/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 000 | Loss: 0.69254 | Correct: 17/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 100 | Loss: 0.69420 | Correct: 14/32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the ensemble\n",
        "acc = ensemble.evaluate(val_loader)         # validation accuracy"
      ],
      "metadata": {
        "id": "3DuQwyK1aHlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K83GOkAGKFI",
        "outputId": "c4429bbc-1088-4e56-c400-dfa3ed4a6c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7GORpdbXxQJ",
        "outputId": "b346d826-6734-4265-9604-23558dba2430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "class DensNet(nn.Module):\n",
        "    def __init__(self, num_classes=2, num_channels=3):\n",
        "        super().__init__()\n",
        "        preloaded = torchvision.models.densenet121(pretrained=True)\n",
        "        self.features = preloaded.features\n",
        "        self.features.conv0 = nn.Conv2d(num_channels, 64, 7, 2, 3)\n",
        "        self.classifier = nn.Linear(1024, num_classes, bias=True)\n",
        "        del preloaded\n",
        "        \n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1)).view(features.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "V1tplRxlXJSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels = 3\n",
        "num_classes = 2\n",
        "base_estimator2 = DensNet(num_classes=num_classes, num_channels=in_channels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "2f42325992694c7ea4f57f8ffe8f7faf",
            "34ab82bc7a1c4798a047c28946c7e4e4",
            "b3ad614c9ee44e16bcc79a923d0cca7b",
            "a69f69efce064dd3aef3c270b3674bdb",
            "86b26e990ded40a19a7f5ecc53102953",
            "f44d7d4ba10a4950bda77300a4da17ad",
            "603f11fb5e7d4b2bb85f8ad713a4b722",
            "dc56506804ea49e5b49184dd98ce7b1b",
            "c8b08b90558e4de18b9d42eb566c159b",
            "8afda8f3b3b84381b3baedda6e8ee4ca",
            "e16b5123449f43b383e8a75dfa541769"
          ]
        },
        "id": "7s2cfGF9XJdB",
        "outputId": "037b00e0-6b27-404e-bc5e-8c1c3d45ac54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/30.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f42325992694c7ea4f57f8ffe8f7faf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.003\n",
        "weight_decay = 0.3\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "0qrtWkwEXfl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchensemble import VotingClassifier"
      ],
      "metadata": {
        "id": "c1U4G9LZXfon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ensemble\n",
        "ensemble = VotingClassifier(\n",
        "    estimator=base_estimator2,              # here is your deep learning model\n",
        "    n_estimators=5,                        # number of base estimators\n",
        ")"
      ],
      "metadata": {
        "id": "xe9ODf1_Xfqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the criterion\n",
        "criterion = nn.CrossEntropyLoss()           # training objective\n",
        "ensemble.set_criterion(criterion)"
      ],
      "metadata": {
        "id": "xiXIsYwAXftK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the optimizer\n",
        "ensemble.set_optimizer(\n",
        "    \"Adam\",                                 # type of parameter optimizer\n",
        "    lr=learning_rate,                       # learning rate of parameter optimizer\n",
        "    weight_decay=weight_decay              # weight decay of parameter optimizer\n",
        ")\n"
      ],
      "metadata": {
        "id": "LIZaqSV8XfvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the learning rate scheduler\n",
        "ensemble.set_scheduler(\n",
        "    \"CosineAnnealingLR\",                    # type of learning rate scheduler\n",
        "    T_max=epochs                           # additional arguments on the scheduler\n",
        ")"
      ],
      "metadata": {
        "id": "8ERZZYBMXfx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the ensemble\n",
        "ensemble.fit(\n",
        "    train_loader,\n",
        "    log_interval=10,\n",
        "    test_loader=val_loader,\n",
        "    epochs=epochs                          # number of training epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csx2Nf4hXf0b",
        "outputId": "ef93fc7e-72b8-4d16-e461-639ccece7126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimator: 000 | Epoch: 000 | Batch: 000 | Loss: 0.75224 | Correct: 14/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 010 | Loss: 0.53421 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 020 | Loss: 0.80177 | Correct: 15/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 030 | Loss: 0.66552 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 040 | Loss: 0.59527 | Correct: 21/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 050 | Loss: 0.60640 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 060 | Loss: 0.54923 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 070 | Loss: 0.59878 | Correct: 21/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 080 | Loss: 0.65911 | Correct: 19/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 090 | Loss: 0.55955 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 100 | Loss: 0.49618 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 110 | Loss: 0.57862 | Correct: 21/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 120 | Loss: 0.58071 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 130 | Loss: 0.63521 | Correct: 19/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 140 | Loss: 0.65525 | Correct: 21/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 150 | Loss: 0.48031 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 160 | Loss: 0.48972 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 170 | Loss: 0.51283 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 000 | Batch: 180 | Loss: 0.36432 | Correct: 29/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 000 | Loss: 0.63417 | Correct: 20/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 010 | Loss: 0.74741 | Correct: 20/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 020 | Loss: 0.58866 | Correct: 20/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 030 | Loss: 0.56770 | Correct: 27/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 040 | Loss: 0.72918 | Correct: 16/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 050 | Loss: 0.66854 | Correct: 21/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 060 | Loss: 0.60027 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 070 | Loss: 0.69636 | Correct: 18/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 080 | Loss: 0.65140 | Correct: 21/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 090 | Loss: 0.70721 | Correct: 14/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 100 | Loss: 0.54145 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 110 | Loss: 0.82864 | Correct: 14/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 120 | Loss: 0.67800 | Correct: 16/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 130 | Loss: 0.72001 | Correct: 14/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 140 | Loss: 0.68992 | Correct: 20/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 150 | Loss: 0.64661 | Correct: 19/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 160 | Loss: 0.67952 | Correct: 19/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 170 | Loss: 0.60910 | Correct: 24/32\n",
            "Estimator: 001 | Epoch: 000 | Batch: 180 | Loss: 0.61251 | Correct: 23/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 000 | Loss: 0.65467 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 010 | Loss: 0.65035 | Correct: 22/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 020 | Loss: 0.80710 | Correct: 14/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 030 | Loss: 0.68060 | Correct: 17/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 040 | Loss: 0.71998 | Correct: 18/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 050 | Loss: 0.67088 | Correct: 17/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 060 | Loss: 0.64567 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 070 | Loss: 0.62147 | Correct: 21/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 080 | Loss: 0.55320 | Correct: 23/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 090 | Loss: 0.83598 | Correct: 16/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 100 | Loss: 0.69960 | Correct: 19/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 110 | Loss: 0.65543 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 120 | Loss: 0.59736 | Correct: 21/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 130 | Loss: 0.69503 | Correct: 18/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 140 | Loss: 0.59903 | Correct: 26/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 150 | Loss: 0.72808 | Correct: 17/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 160 | Loss: 0.56084 | Correct: 21/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 170 | Loss: 0.72245 | Correct: 13/32\n",
            "Estimator: 002 | Epoch: 000 | Batch: 180 | Loss: 0.71632 | Correct: 12/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 000 | Loss: 0.69291 | Correct: 18/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 010 | Loss: 0.60343 | Correct: 23/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 020 | Loss: 0.67908 | Correct: 24/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 030 | Loss: 0.62819 | Correct: 22/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 040 | Loss: 0.84943 | Correct: 13/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 050 | Loss: 0.68630 | Correct: 23/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 060 | Loss: 0.70900 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 070 | Loss: 0.67077 | Correct: 26/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 080 | Loss: 0.60751 | Correct: 22/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 090 | Loss: 0.65202 | Correct: 20/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 100 | Loss: 0.56411 | Correct: 24/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 110 | Loss: 0.62657 | Correct: 19/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 120 | Loss: 0.64041 | Correct: 20/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 130 | Loss: 0.67993 | Correct: 18/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 140 | Loss: 0.59482 | Correct: 24/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 150 | Loss: 0.70382 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 160 | Loss: 0.68861 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 170 | Loss: 0.63313 | Correct: 22/32\n",
            "Estimator: 003 | Epoch: 000 | Batch: 180 | Loss: 0.64775 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 000 | Loss: 0.62789 | Correct: 22/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 010 | Loss: 0.69808 | Correct: 20/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 020 | Loss: 0.86392 | Correct: 16/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 030 | Loss: 0.69308 | Correct: 17/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 040 | Loss: 0.75531 | Correct: 18/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 050 | Loss: 0.59452 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 060 | Loss: 0.63895 | Correct: 18/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 070 | Loss: 0.61724 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 080 | Loss: 0.61379 | Correct: 23/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 090 | Loss: 0.63506 | Correct: 23/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 100 | Loss: 0.66433 | Correct: 19/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 110 | Loss: 0.66100 | Correct: 19/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 120 | Loss: 0.66989 | Correct: 18/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 130 | Loss: 0.56170 | Correct: 25/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 140 | Loss: 0.64641 | Correct: 18/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 150 | Loss: 0.64712 | Correct: 24/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 160 | Loss: 0.66029 | Correct: 18/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 170 | Loss: 0.70971 | Correct: 17/32\n",
            "Estimator: 004 | Epoch: 000 | Batch: 180 | Loss: 0.57323 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 000 | Loss: 0.54695 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 010 | Loss: 0.62139 | Correct: 20/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 020 | Loss: 0.63305 | Correct: 21/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 030 | Loss: 0.50837 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 040 | Loss: 0.46977 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 050 | Loss: 0.59041 | Correct: 21/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 060 | Loss: 0.56472 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 070 | Loss: 0.46248 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 080 | Loss: 0.49661 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 090 | Loss: 0.55207 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 100 | Loss: 0.52347 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 110 | Loss: 0.52318 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 120 | Loss: 0.48666 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 130 | Loss: 0.56035 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 140 | Loss: 0.56809 | Correct: 20/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 150 | Loss: 0.65265 | Correct: 21/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 160 | Loss: 0.47841 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 170 | Loss: 0.51784 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 001 | Batch: 180 | Loss: 0.50023 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 000 | Loss: 0.67519 | Correct: 16/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 010 | Loss: 0.55345 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 020 | Loss: 0.51561 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 030 | Loss: 0.59716 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 040 | Loss: 0.74405 | Correct: 16/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 050 | Loss: 0.63001 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 060 | Loss: 0.59850 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 070 | Loss: 0.60323 | Correct: 20/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 080 | Loss: 0.63943 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 090 | Loss: 0.70305 | Correct: 15/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 100 | Loss: 0.62514 | Correct: 19/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 110 | Loss: 0.66247 | Correct: 19/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 120 | Loss: 0.56906 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 130 | Loss: 0.58646 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 140 | Loss: 0.62927 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 150 | Loss: 0.54703 | Correct: 24/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 160 | Loss: 0.62592 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 170 | Loss: 0.63976 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 001 | Batch: 180 | Loss: 0.49274 | Correct: 25/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 000 | Loss: 0.66576 | Correct: 23/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 010 | Loss: 0.67824 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 020 | Loss: 0.68243 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 030 | Loss: 0.66690 | Correct: 18/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 040 | Loss: 0.60929 | Correct: 21/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 050 | Loss: 0.65123 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 060 | Loss: 0.65252 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 070 | Loss: 0.55627 | Correct: 23/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 080 | Loss: 0.61627 | Correct: 19/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 090 | Loss: 0.66494 | Correct: 16/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 100 | Loss: 0.69243 | Correct: 16/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 110 | Loss: 0.66155 | Correct: 21/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 120 | Loss: 0.61495 | Correct: 22/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 130 | Loss: 0.63326 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 140 | Loss: 0.72598 | Correct: 16/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 150 | Loss: 0.59763 | Correct: 24/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 160 | Loss: 0.72011 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 170 | Loss: 0.69903 | Correct: 14/32\n",
            "Estimator: 002 | Epoch: 001 | Batch: 180 | Loss: 0.59360 | Correct: 22/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 000 | Loss: 0.59732 | Correct: 24/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 010 | Loss: 0.58871 | Correct: 24/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 020 | Loss: 0.67883 | Correct: 21/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 030 | Loss: 0.67799 | Correct: 18/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 040 | Loss: 0.64496 | Correct: 24/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 050 | Loss: 0.64506 | Correct: 22/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 060 | Loss: 0.61116 | Correct: 24/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 070 | Loss: 0.59679 | Correct: 23/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 080 | Loss: 0.63517 | Correct: 20/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 090 | Loss: 0.64089 | Correct: 23/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 100 | Loss: 0.64597 | Correct: 20/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 110 | Loss: 0.67204 | Correct: 16/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 120 | Loss: 0.61393 | Correct: 23/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 130 | Loss: 0.66036 | Correct: 22/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 140 | Loss: 0.63699 | Correct: 20/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 150 | Loss: 0.59839 | Correct: 27/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 160 | Loss: 0.68145 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 170 | Loss: 0.67935 | Correct: 18/32\n",
            "Estimator: 003 | Epoch: 001 | Batch: 180 | Loss: 0.69412 | Correct: 13/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 000 | Loss: 0.62943 | Correct: 23/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 010 | Loss: 0.62698 | Correct: 26/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 020 | Loss: 0.65183 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 030 | Loss: 0.63408 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 040 | Loss: 0.61512 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 050 | Loss: 0.62384 | Correct: 24/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 060 | Loss: 0.61497 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 070 | Loss: 0.69289 | Correct: 20/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 080 | Loss: 0.64812 | Correct: 19/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 090 | Loss: 0.79335 | Correct: 14/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 100 | Loss: 0.54649 | Correct: 26/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 110 | Loss: 0.63426 | Correct: 24/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 120 | Loss: 0.64988 | Correct: 18/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 130 | Loss: 0.58777 | Correct: 23/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 140 | Loss: 0.61193 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 150 | Loss: 0.69841 | Correct: 19/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 160 | Loss: 0.61871 | Correct: 23/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 170 | Loss: 0.63732 | Correct: 22/32\n",
            "Estimator: 004 | Epoch: 001 | Batch: 180 | Loss: 0.67556 | Correct: 19/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 000 | Loss: 0.53795 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 010 | Loss: 0.50167 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 020 | Loss: 0.54670 | Correct: 21/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 030 | Loss: 0.51579 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 040 | Loss: 0.53530 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 050 | Loss: 0.55322 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 060 | Loss: 0.49020 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 070 | Loss: 0.53998 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 080 | Loss: 0.50758 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 090 | Loss: 0.48002 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 100 | Loss: 0.56128 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 110 | Loss: 0.43806 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 120 | Loss: 0.50936 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 130 | Loss: 0.51920 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 140 | Loss: 0.53877 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 150 | Loss: 0.53225 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 160 | Loss: 0.58519 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 170 | Loss: 0.53425 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 002 | Batch: 180 | Loss: 0.44870 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 000 | Loss: 0.65789 | Correct: 18/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 010 | Loss: 0.53653 | Correct: 24/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 020 | Loss: 0.61219 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 030 | Loss: 0.60546 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 040 | Loss: 0.56796 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 050 | Loss: 0.60913 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 060 | Loss: 0.63100 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 070 | Loss: 0.62384 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 080 | Loss: 0.65746 | Correct: 21/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 090 | Loss: 0.54015 | Correct: 24/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 100 | Loss: 0.48357 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 110 | Loss: 0.58464 | Correct: 20/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 120 | Loss: 0.63572 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 130 | Loss: 0.58741 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 140 | Loss: 0.52879 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 150 | Loss: 0.51604 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 160 | Loss: 0.54051 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 170 | Loss: 0.58679 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 002 | Batch: 180 | Loss: 0.50984 | Correct: 24/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 000 | Loss: 0.57418 | Correct: 25/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 010 | Loss: 0.66949 | Correct: 17/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 020 | Loss: 0.66811 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 030 | Loss: 0.62153 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 040 | Loss: 0.70679 | Correct: 17/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 050 | Loss: 0.63186 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 060 | Loss: 0.66876 | Correct: 18/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 070 | Loss: 0.67865 | Correct: 18/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 080 | Loss: 0.63706 | Correct: 22/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 090 | Loss: 0.60621 | Correct: 23/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 100 | Loss: 0.59040 | Correct: 25/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 110 | Loss: 0.56410 | Correct: 25/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 120 | Loss: 0.55532 | Correct: 24/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 130 | Loss: 0.65154 | Correct: 18/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 140 | Loss: 0.70669 | Correct: 18/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 150 | Loss: 0.63501 | Correct: 20/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 160 | Loss: 0.58037 | Correct: 24/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 170 | Loss: 0.56465 | Correct: 25/32\n",
            "Estimator: 002 | Epoch: 002 | Batch: 180 | Loss: 0.57614 | Correct: 23/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 000 | Loss: 0.71060 | Correct: 12/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 010 | Loss: 0.69637 | Correct: 14/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 020 | Loss: 0.69151 | Correct: 18/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 030 | Loss: 0.69475 | Correct: 14/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 040 | Loss: 0.69404 | Correct: 14/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 050 | Loss: 0.68878 | Correct: 20/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 060 | Loss: 0.69181 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 070 | Loss: 0.69546 | Correct: 14/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 080 | Loss: 0.69320 | Correct: 16/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 090 | Loss: 0.69321 | Correct: 16/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 100 | Loss: 0.69295 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 110 | Loss: 0.69321 | Correct: 15/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 120 | Loss: 0.69314 | Correct: 16/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 130 | Loss: 0.69314 | Correct: 19/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 140 | Loss: 0.69280 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 150 | Loss: 0.69257 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 160 | Loss: 0.69233 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 170 | Loss: 0.69436 | Correct: 15/32\n",
            "Estimator: 003 | Epoch: 002 | Batch: 180 | Loss: 0.69754 | Correct: 12/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 000 | Loss: 0.56895 | Correct: 27/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 010 | Loss: 0.69942 | Correct: 19/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 020 | Loss: 0.63493 | Correct: 20/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 030 | Loss: 0.67372 | Correct: 17/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 040 | Loss: 0.71428 | Correct: 17/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 050 | Loss: 0.70753 | Correct: 19/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 060 | Loss: 0.67253 | Correct: 18/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 070 | Loss: 0.52675 | Correct: 26/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 080 | Loss: 0.58431 | Correct: 24/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 090 | Loss: 0.58217 | Correct: 23/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 100 | Loss: 0.57645 | Correct: 24/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 110 | Loss: 0.63115 | Correct: 22/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 120 | Loss: 0.62397 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 130 | Loss: 0.61706 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 140 | Loss: 0.66338 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 150 | Loss: 0.74189 | Correct: 15/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 160 | Loss: 0.58960 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 170 | Loss: 0.62245 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 002 | Batch: 180 | Loss: 0.60933 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 000 | Loss: 0.58904 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 010 | Loss: 0.55719 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 020 | Loss: 0.56001 | Correct: 21/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 030 | Loss: 0.55112 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 040 | Loss: 0.46091 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 050 | Loss: 0.48069 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 060 | Loss: 0.65520 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 070 | Loss: 0.51691 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 080 | Loss: 0.45032 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 090 | Loss: 0.49957 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 100 | Loss: 0.58116 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 110 | Loss: 0.45624 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 120 | Loss: 0.48532 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 130 | Loss: 0.52448 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 140 | Loss: 0.58368 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 150 | Loss: 0.72553 | Correct: 18/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 160 | Loss: 0.44083 | Correct: 28/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 170 | Loss: 0.55923 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 003 | Batch: 180 | Loss: 0.45240 | Correct: 27/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 000 | Loss: 0.54078 | Correct: 27/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 010 | Loss: 0.66003 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 020 | Loss: 0.52073 | Correct: 24/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 030 | Loss: 0.60539 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 040 | Loss: 0.51446 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 050 | Loss: 0.50367 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 060 | Loss: 0.49406 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 070 | Loss: 0.56291 | Correct: 19/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 080 | Loss: 0.54339 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 090 | Loss: 0.59320 | Correct: 20/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 100 | Loss: 0.59273 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 110 | Loss: 0.74695 | Correct: 17/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 120 | Loss: 0.56465 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 130 | Loss: 0.53741 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 140 | Loss: 0.53936 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 150 | Loss: 0.49921 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 160 | Loss: 0.63272 | Correct: 20/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 170 | Loss: 0.55593 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 003 | Batch: 180 | Loss: 0.48669 | Correct: 26/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 000 | Loss: 0.62597 | Correct: 24/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 010 | Loss: 0.66864 | Correct: 21/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 020 | Loss: 0.61861 | Correct: 22/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 030 | Loss: 0.54946 | Correct: 23/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 040 | Loss: 0.55838 | Correct: 26/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 050 | Loss: 0.52006 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 060 | Loss: 0.59678 | Correct: 21/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 070 | Loss: 0.49688 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 080 | Loss: 0.67065 | Correct: 17/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 090 | Loss: 0.59885 | Correct: 23/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 100 | Loss: 0.63552 | Correct: 22/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 110 | Loss: 0.62908 | Correct: 22/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 120 | Loss: 0.62365 | Correct: 24/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 130 | Loss: 0.72570 | Correct: 16/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 140 | Loss: 0.60099 | Correct: 22/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 150 | Loss: 0.67119 | Correct: 17/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 160 | Loss: 0.51515 | Correct: 27/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 170 | Loss: 0.56807 | Correct: 22/32\n",
            "Estimator: 002 | Epoch: 003 | Batch: 180 | Loss: 0.66013 | Correct: 22/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 000 | Loss: 0.69035 | Correct: 19/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 010 | Loss: 0.69010 | Correct: 19/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 020 | Loss: 0.69329 | Correct: 16/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 030 | Loss: 0.69526 | Correct: 14/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 040 | Loss: 0.69236 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 050 | Loss: 0.69319 | Correct: 16/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 060 | Loss: 0.69580 | Correct: 11/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 070 | Loss: 0.69319 | Correct: 16/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 080 | Loss: 0.69606 | Correct: 12/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 090 | Loss: 0.69390 | Correct: 15/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 100 | Loss: 0.69384 | Correct: 15/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 110 | Loss: 0.69164 | Correct: 19/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 120 | Loss: 0.69422 | Correct: 13/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 130 | Loss: 0.69365 | Correct: 14/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 140 | Loss: 0.69274 | Correct: 18/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 150 | Loss: 0.69512 | Correct: 10/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 160 | Loss: 0.69171 | Correct: 21/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 170 | Loss: 0.69383 | Correct: 15/32\n",
            "Estimator: 003 | Epoch: 003 | Batch: 180 | Loss: 0.69456 | Correct: 14/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 000 | Loss: 0.66837 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 010 | Loss: 0.58219 | Correct: 24/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 020 | Loss: 0.54158 | Correct: 29/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 030 | Loss: 0.53787 | Correct: 28/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 040 | Loss: 0.65759 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 050 | Loss: 0.63010 | Correct: 22/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 060 | Loss: 0.64799 | Correct: 22/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 070 | Loss: 0.60663 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 080 | Loss: 0.62473 | Correct: 22/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 090 | Loss: 0.60756 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 100 | Loss: 0.59998 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 110 | Loss: 0.68180 | Correct: 19/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 120 | Loss: 0.58368 | Correct: 23/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 130 | Loss: 0.62688 | Correct: 20/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 140 | Loss: 0.60345 | Correct: 22/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 150 | Loss: 0.58522 | Correct: 24/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 160 | Loss: 0.64512 | Correct: 20/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 170 | Loss: 0.72159 | Correct: 15/32\n",
            "Estimator: 004 | Epoch: 003 | Batch: 180 | Loss: 0.69371 | Correct: 16/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 000 | Loss: 0.58388 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 010 | Loss: 0.49623 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 020 | Loss: 0.50797 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 030 | Loss: 0.48444 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 040 | Loss: 0.58375 | Correct: 23/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 050 | Loss: 0.45222 | Correct: 27/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 060 | Loss: 0.50043 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 070 | Loss: 0.52812 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 080 | Loss: 0.49974 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 090 | Loss: 0.65432 | Correct: 20/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 100 | Loss: 0.56055 | Correct: 21/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 110 | Loss: 0.47237 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 120 | Loss: 0.50981 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 130 | Loss: 0.57688 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 140 | Loss: 0.43224 | Correct: 26/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 150 | Loss: 0.54067 | Correct: 22/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 160 | Loss: 0.44943 | Correct: 25/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 170 | Loss: 0.57914 | Correct: 24/32\n",
            "Estimator: 000 | Epoch: 004 | Batch: 180 | Loss: 0.51413 | Correct: 24/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 000 | Loss: 0.47814 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 010 | Loss: 0.48637 | Correct: 24/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 020 | Loss: 0.45337 | Correct: 27/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 030 | Loss: 0.48039 | Correct: 27/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 040 | Loss: 0.58810 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 050 | Loss: 0.49921 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 060 | Loss: 0.51792 | Correct: 24/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 070 | Loss: 0.48521 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 080 | Loss: 0.46291 | Correct: 28/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 090 | Loss: 0.58866 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 100 | Loss: 0.43987 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 110 | Loss: 0.56918 | Correct: 23/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 120 | Loss: 0.49754 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 130 | Loss: 0.57255 | Correct: 22/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 140 | Loss: 0.49407 | Correct: 24/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 150 | Loss: 0.55791 | Correct: 24/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 160 | Loss: 0.52432 | Correct: 26/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 170 | Loss: 0.53275 | Correct: 25/32\n",
            "Estimator: 001 | Epoch: 004 | Batch: 180 | Loss: 0.53089 | Correct: 25/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 000 | Loss: 0.60589 | Correct: 21/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 010 | Loss: 0.54817 | Correct: 24/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 020 | Loss: 0.62564 | Correct: 21/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 030 | Loss: 0.53260 | Correct: 25/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 040 | Loss: 0.54930 | Correct: 25/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 050 | Loss: 0.56501 | Correct: 23/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 060 | Loss: 0.66041 | Correct: 17/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 070 | Loss: 0.60885 | Correct: 24/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 080 | Loss: 0.52966 | Correct: 28/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 090 | Loss: 0.66092 | Correct: 19/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 100 | Loss: 0.59228 | Correct: 23/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 110 | Loss: 0.63126 | Correct: 23/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 120 | Loss: 0.62197 | Correct: 23/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 130 | Loss: 0.58961 | Correct: 23/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 140 | Loss: 0.58201 | Correct: 22/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 150 | Loss: 0.61449 | Correct: 21/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 160 | Loss: 0.58190 | Correct: 25/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 170 | Loss: 0.59471 | Correct: 21/32\n",
            "Estimator: 002 | Epoch: 004 | Batch: 180 | Loss: 0.56288 | Correct: 22/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 000 | Loss: 0.69569 | Correct: 12/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 010 | Loss: 0.69665 | Correct: 10/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 020 | Loss: 0.69263 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 030 | Loss: 0.69370 | Correct: 15/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 040 | Loss: 0.69319 | Correct: 16/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 050 | Loss: 0.69443 | Correct: 14/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 060 | Loss: 0.69257 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 070 | Loss: 0.69257 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 080 | Loss: 0.69198 | Correct: 18/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 090 | Loss: 0.69195 | Correct: 18/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 100 | Loss: 0.69382 | Correct: 15/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 110 | Loss: 0.69131 | Correct: 19/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 120 | Loss: 0.69253 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 130 | Loss: 0.69254 | Correct: 17/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 140 | Loss: 0.69517 | Correct: 13/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 150 | Loss: 0.69075 | Correct: 20/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 160 | Loss: 0.69503 | Correct: 13/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 170 | Loss: 0.69145 | Correct: 19/32\n",
            "Estimator: 003 | Epoch: 004 | Batch: 180 | Loss: 0.69486 | Correct: 13/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 000 | Loss: 0.58311 | Correct: 25/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 010 | Loss: 0.64477 | Correct: 22/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 020 | Loss: 0.71168 | Correct: 15/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 030 | Loss: 0.60204 | Correct: 24/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 040 | Loss: 0.60004 | Correct: 24/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 050 | Loss: 0.59380 | Correct: 25/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 060 | Loss: 0.52423 | Correct: 26/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 070 | Loss: 0.64524 | Correct: 20/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 080 | Loss: 0.61028 | Correct: 24/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 090 | Loss: 0.62206 | Correct: 22/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 100 | Loss: 0.60503 | Correct: 24/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 110 | Loss: 0.65942 | Correct: 19/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 120 | Loss: 0.65817 | Correct: 19/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 130 | Loss: 0.59920 | Correct: 20/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 140 | Loss: 0.61206 | Correct: 21/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 150 | Loss: 0.53543 | Correct: 26/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 160 | Loss: 0.61031 | Correct: 22/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 170 | Loss: 0.64035 | Correct: 19/32\n",
            "Estimator: 004 | Epoch: 004 | Batch: 180 | Loss: 0.61379 | Correct: 22/32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the ensemble\n",
        "acc = ensemble.evaluate(test_loader)         # validation accuracy"
      ],
      "metadata": {
        "id": "K6YFkWwzXf2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPcokfJoXf5V",
        "outputId": "c405384c-e16f-4e51-cb11-b7ddf6a8a77e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78.1718963165075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UsfxlwJxXf_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SAbpxkSLXgCo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}